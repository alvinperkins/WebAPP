






data = {


"blog":
{"captionU":"github.com",
 "captionT":"blogs talk on spark",
 "headlines":[("http://www.cnblogs.com/sparkbigdata/p/5448673.html","","yongbufushu 2016"),
              ("http://blog.csdn.net/qq_21234493/article/details/51339450","","spark duan"),
              ("http://blog.sina.com.cn/s/blog_9ca9623b0102wcz9.html","","spark machine learning"),
              ("http://blog.csdn.net/tanglizhe1105/article/details/50530104","","tanglizhi"),
              ("http://flyingdutchman.iteye.com/category/273190","","hadoop"),
              ("http://www.cloudera.com/documentation/archive/impala/2-x/2-0-x/topics/impala_group_by.html","","hive"),
              ("http://m.blog.csdn.net/blog/index?username=snail_gesture","","snail_guesture"),
              ("http://m.blog.csdn.net/article/details?id=51590390","","streaming project"),
              ("http://blog.csdn.net/andie_guo/article/details/44086231","","hadoop example")]
},
"stackoverflow":
{"captionU":"",
 "captionT":"various QA from site stackoverflow",
 "headlines":[("http://stackoverflow.com/questions/1051640/correct-way-to-add-external-jars-lib-jar-to-an-intellij-idea-project","","add external jar")]
}, 

"this":

{
 "captionU":"",
"captionT":"",

"headlines" : [("http://spark.apache.org/docs/latest/job-scheduling.html","","Inside DAGScheduler"),
("/code/sparkx/scheduler/DAGScheduler.txt","","The high-level scheduling layer"),
("/code/sparkx/scheduler/TaskSchedulerImpl.txt","","TaskSchedulerImpl: submit task sets"),
("/code/sparkx/scheduler/cluster/CoarseGrainedSchedulerBackend.txt","","launch tasks")]
},
"index":{
         "captionU":"/static/sparkx/index/api-doc.htm",
         "captionT":"programing scala",
         "headlines":[("/static/sparkx/index/newArray.txt","","new Array[Any]"),
                      ("/static/sparkx/index/logTrace.txt","","logTrace"),
                      ("/static/sparkx/index/loginfo.txt","","logInfo"),
                      ("/static/sparkx/index/logError","","logError"),
                      ("/static/sparkx/index/logWarning","","logWarning")]
},
"redis":{
         "captionT":"tao bao- yaoyiyao-",
         "captionU":"any thing is hot",
         "headlines":[("http://sannong.cntv.cn/program/zhifujing/20120821/100050_2.shtml","","[to be rich] feed 1fish like wine"),
                      ("","","")]
         },

"archive":{
    "captionU":"chrome://bookmarks",
    "captionT": "publiced topics",
    "headlines":[("/topic/Tungsten","","OffHeap Memory Manage : faster"),
                 ("/topic/IDE","","IDEs, plugins, clusters, datasources,networks...")]
},
"Tungsten":

{


},
"topic":{
         "captionU":"/topic/topic",
         "captionT":"new topic",
         "headlines":[("http://www.useit.com.cn/","","trend report"),
                      ("/static/index/spark 2.0 -- Google Search.htm",""," spark 2.0"),
                      ("/topic/wechat","","public article"),
                      ("/static/sparkx/index/api-doc.htm",""," see official document"),
                      ("http://www.ehow.com/how_7510665_talk-girl-stranger.html","","How to Talk to a Girl Who Is a Stranger?")]
},
"wechat":{
          "captionU":"http://mp.weixin.qq.com/s?__biz=MzA4MjI2MTcwMw==&mid=400764277&idx=1&sn=e1545112a7a079f4a67825c4ab77c4db&3rd=MzA3MDU4NTYzMw==&scene=6#rd",
          "captionT":"saved article",
          "headlines":[("/static/index/tobe.txt","","my article"),
                       ("https://mail.qq.com","","login")]
},
"IDE":{
        "captionU":"http://docs.scala-lang.org/overviews/",
        "captionT": "IDE environment",
        "headlines":[("http://my.oschina.net/muou/blog/408543?fromerr=EZyMGV8e","2016/4/17","environment for hadoop application"),
                     ("http://www.cnblogs.com/syveen/archive/2013/05/08/3068044.html","how to config ?","from zero"),
                     ("/topic/hadoop","","topic hadoop"),
                     ("http://my.oschina.net/corleone/blog?catalog=106499","","corleone's blog")]
},
"hadoop":{
          "captionU":"http://lib.csdn.net/base/20?source=blogtop",
          "captionT":" hadoop knowledge",
          "headlines":[("http://hadoop.apache.org/docs/r2.6.4/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html","","HDFS Commands & File System shell"),
                       ("http://hadoop.apache.org/docs/r2.6.4/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html","","Map Reduce Tutorial")]
},
"RDDdeps":{},
"streaming":{
             "captionU":"/code/sparkx/streaming/dstream/DStream.txt",
             "captionT":"streaming",
             "headlines":[("/topic/flume","","flume"),
                          ("/topic/kafka","","kafka")]
},
"kafka":{
         "captionU":"http://www.infoq.com/cn/kafka/",
         "captionT":".",
         "headlines":[("http://www.infoq.com/cn/kafka/","","kafka on infoQ"),
                      ]
},
"flume":{
         "captionU":"http://flume.apache.org/FlumeUserGuide.html",
         "captionT":"Flume",
         "headlines":[("http://blog.csdn.net/lskyne/article/details/37531099","","install flume"),
                      ("http://www.aboutyun.com/thread-6247-1-1.html","","fault tolerant")]
},

"sched":{
 "captionU":"",
"captionT":"catalyst ...",

"headlines" : [("http://spark.apache.org/docs/latest/job-scheduling.html","","Inside DAGScheduler"),
("/code/sparkx/scheduler/DAGScheduler.txt","","The high-level scheduling layer"),
("/code/sparkx/scheduler/TaskSchedulerImpl.txt","","TaskSchedulerImpl: submit task sets"),
("/code/sparkx/scheduler/cluster/CoarseGrainedSchedulerBackend.txt","","launch tasks")]

},
"welcome":{
         "captionU":"",
         "captionT":"Lightning-fast cluster computing",

         "headlines" : [("http://view.news.qq.com/original/intouchtoday/n3928.html","","")
             ]

         },


}






config = {
          "sched":{
 "captionU":"",
"captionT":"new",

"headlines" : [("http://spark.apache.org/docs/latest/job-scheduling.html","","Inside DAGScheduler"),
("/code/sparkx/scheduler/DAGScheduler.txt","","The high-level scheduling layer"),
("/code/sparkx/scheduler/TaskSchedulerImpl.txt","","TaskSchedulerImpl: submit task sets"),
("/code/sparkx/scheduler/cluster/CoarseGrainedSchedulerBackend.txt","","launch tasks")]

}
          }
